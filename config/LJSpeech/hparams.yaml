lang: "en"
text_cleaners: ["english_cleaners"]

train:
  epochs: 500
  iters_per_checkpoint: 10000
  iters_per_validation: 100
  batch_size: 32
  seed: 1234
  dynamic_loss_scaling: True
  fp16_run: False
  distributed_run: False
  cudnn_enabled: True
  cudnn_benchmark: False
  ignore_layers: ["embedding.weight"]
  output_dir: "out"
  log_dir: "log"
  result_dir: "result"
  checkpoint_path: ""

dataset:
  data_path: "/data/training_data/preprocessed_data/LJSpeech/"
  lexicon_path: "lexicon/librispeech-lexicon.txt"
  training_files: "preprocessed_data/LJSpeech/train.txt"
  validation_files: "preprocessed_data/LJSpeech/val.txt"
  
model:
  tacotron_version: "2"  
  tacotron_config: "config/tacotron2.json"
  symbols_embed_dim: 512
  mel_dim: 80
  r: 3
  max_decoder_steps: 1000
  stop_threshold: 0.5
  # additional parameters
  use_bert: True
  use_bert_type: "lstm"  # direct or lstm
  bert_dim: 768
  use_dependency: True
  graph_type: "rev_type"

optimization:
  use_saved_learning_rate: False
  learning_rate: 0.001
  weight_decay: 0.000001
  grad_clip_thresh: 1.0
  mask_padding: True

audio:
  max_wav_value: 32767.0
  hop_length: 256
  win_length: 1024
  filter_length: 1024
  sampling_rate: 22050
 
vocoder:
  config: "hifigan/config_22k.json"
  ckpt: "/apdcephfs/private_yatsenzhou/pretrained/hifigan/LJSpeech_22k/generator_LJSpeech.pth.tar"

  
  
